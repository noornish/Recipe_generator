{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9823dd31-d8f0-4f50-8bf7-82316d76d844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/envs/pytorch-gpu/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: ''If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import intel_extension_for_pytorch as ipex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7d1f0f-5cd1-4932-94c4-6e308dfe719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 20:39:50.111971: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-02 20:39:50.238312: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 20:39:50.790759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-02 20:39:50.790818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-02 20:39:50.917702: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-02 20:39:51.157702: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 20:39:51.160529: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 20:39:53.937449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-02 20:39:57.623494: I itex/core/wrapper/itex_cpu_wrapper.cc:60] Intel Extension for Tensorflow* AVX512 CPU backend is loaded.\n",
      "2024-04-02 20:39:59,221 - datasets - INFO - PyTorch version 2.0.1a0+cxx11.abi available.\n",
      "2024-04-02 20:39:59,223 - datasets - INFO - TensorFlow version 2.15.1 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb650de5-346f-468b-8e0d-22a667c776fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv('Cleaned_Indian_Food_Dataset.csv').head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ecadce-26d0-4631-8877-0394d37d3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f61167-e05a-495d-84a1-0760fa7f3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './100GPT1api'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03faa4a9-5cc5-4f80-8f78-0d4714dd4172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706d3c7e88444a0eb9a036a8609aea44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c121c0bc9cf54a158d19961a8a550da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368fa1b590b04e5f88eaa888d5017d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177925c70d9b4b6bb0a182b61a6b01bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cad59557934e9cabc5d15f061207a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d85f2a71b104dadac2091421c7919cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a8eeeb8df54504a0fa8b19daf700ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_name,\n",
    "                                              bos_token='<|startoftext|>',\n",
    "                                              eos_token='<|endoftext|>',\n",
    "                                              unk_token='<|unknown|>',\n",
    "                                              pad_token='<|pad|>'\n",
    "                                             )\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440f8612-0484-4819-98cb-4df7d1ec4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f202bac3-4609-4c55-8e8b-9b403f68a172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./100GPT1api/tokenizer_config.json',\n",
       " './100GPT1api/special_tokens_map.json',\n",
       " './100GPT1api/vocab.json',\n",
       " './100GPT1api/merges.txt',\n",
       " './100GPT1api/added_tokens.json',\n",
       " './100GPT1api/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c39b43f7-eb61-409e-a138-69a6f4b3d690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50259]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['<|pad|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e8100e-8d9d-4871-bff0-4de826e95b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "    inputs = tokenizer.encode_plus(prompt, return_tensors='pt')\n",
    "    output = model.generate(**inputs, max_length=max_length, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "    print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f500589d-1974-410a-bf4a-47152018fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean.sample(frac=1)\n",
    "clean.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d4799f1-e7c5-45e0-a0e6-8d727620b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(train_size * len(clean))\n",
    "clean = clean[:train_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5dfc1fb-33fe-4a38-bc7a-00fdaab18841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|startoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|unknown|>',\n",
       " 'pad_token': '<|pad|>'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f9bc92e-1931-46a2-a09d-42a9c13682e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50257]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['<|startoftext|>'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c885ace4-8c3b-4b59-938e-c6bddbf4c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean = clean.sample(frac=1)\n",
    "clean.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57e836c3-320f-4d5f-b0be-7b48f7b6dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recipe(idx):\n",
    "    print(f\"{clean['ingredients'][idx]}\\n\\n{clean['instructions'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79c91c1c-5245-4622-aa9d-af234aba297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_string(ingredient, instruction):\n",
    "    s = f\"Ingredients:\\n{ingredient.strip()}\\n\\nInstructions:\\n{instruction.strip()}\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da531377-0b8b-42b0-b426-9a30b028bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TranslatedRecipeName', 'TranslatedIngredients', 'TotalTimeInMins',\n",
      "       'Cuisine', 'TranslatedInstructions', 'URL', 'Cleaned-Ingredients',\n",
      "       'image-url', 'Ingredient-count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6236e3b1-f67d-4368-a7d5-3109212f706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean.apply(lambda x: form_string(x['Cleaned-Ingredients'], x['TranslatedInstructions']), axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eda67629-93f9-42a5-bc8c-768b52c4df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.85\n",
    "train_len = int(train_size * len(data))\n",
    "train_data = data[:train_len]\n",
    "val_data = data[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8fa1e4f-d165-481a-bd47-0dd358a7694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "        for item in tqdm(data):\n",
    "            encodings = tokenizer.encode_plus(item,\n",
    "                                              truncation=True,\n",
    "                                              padding='max_length',\n",
    "                                              max_length=max_length,  # Adjusted max_length\n",
    "                                              return_tensors='pt'\n",
    "                                             )\n",
    "            self.input_ids.append(torch.squeeze(encodings['input_ids'], 0))\n",
    "            self.attn_masks.append(torch.squeeze(encodings['attention_mask'], 0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e63dc80-a521-4727-bb35-3a63ea92830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04c9b46f1084ddb9d13c13a231afa8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = RecipeDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a1b176f-4c3f-4f17-91a5-df0c79a441a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c09b88b0-3f88-4553-b216-7a8721beaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'input_ids': torch.stack([item[0] for item in batch]),\n",
    "        'attention_mask': torch.stack([item[1] for item in batch]),\n",
    "        'labels': torch.stack([item[0] for item in batch])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "549b0e61-ad0d-479e-ae2d-123e6c4b4781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c20c3d87b94b499122ddfa2ee1f343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93f42bc540e4efcac5ff5d65afe748f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = RecipeDataset(train_data)\n",
    "val_ds = RecipeDataset(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35ed1743-12bd-4a5b-8c9e-584311e864aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(output_dir=model_save_path,\n",
    "                         per_device_train_batch_size=batch_size,\n",
    "                         per_device_eval_batch_size=batch_size,\n",
    "                         gradient_accumulation_steps=2,\n",
    "                         report_to='none',\n",
    "                         num_train_epochs=10,\n",
    "                         save_strategy='no',\n",
    "                         use_ipex=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "299c2397-aa31-4971-9e88-74115870ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optim, 20, eta_min=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae05c8f7-d5db-4753-a49f-a374140c1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model,\n",
    "                  args,\n",
    "                  train_dataset=train_ds,\n",
    "                  eval_dataset=train_ds,  # Using train_ds for evaluation for now, change it as needed\n",
    "                  data_collator=collate_fn,\n",
    "                  optimizers=(optim, scheduler)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df019829-f714-4c19-99a3-7460e85f9f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1490' max='1490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1490/1490 03:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.489900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.296900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1490, training_loss=1.3240393721817323, metrics={'train_runtime': 233.2246, 'train_samples_per_second': 25.512, 'train_steps_per_second': 6.389, 'total_flos': 1554687590400000.0, 'train_loss': 1.3240393721817323, 'epoch': 10.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9af2d54-08f2-4c95-b3e9-8513251035af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5874ba0b-eeb2-41ce-9207-5015cbc02ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"gptmodel/\"\n",
    "trainer.save_model(model_save_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378f420-2494-457b-b119-063147289607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
